{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4fhror4LEgr"
   },
   "source": [
    "iStudy ACADEMY 現場で潰しが効くディープラーニング講座 視聴課題レポート 応用数学（講義動画）\n",
    "<div style=\"text-align: right;\">【レポート作成者】S.Honda</div>\n",
    "\n",
    "# 応用数学\n",
    "\n",
    "## 参考文献・URL\n",
    "\n",
    "- 線形代数・固有値計算 [大学1年生もバッチリ分かる線形代数入門](https://oguemon.com/topic/study/linear-algebra/)\n",
    "- 確率分布・分散 [統計WEB](https://bellcurve.jp/statistics/course/#step01-009)\n",
    "- 情報理論・エントロピー [情報理論の基礎～情報量の定義から相対エントロピー、相互情報量まで～](https://logics-of-blue.com/information-theory-basic/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "erWaiWY6VPQ9"
   },
   "source": [
    "# 第１章：線形代数\n",
    "\n",
    "- 線形はLinerという意味\n",
    "- １次関数みたいな関数同士の足し算が関数の中身の足し算になる\n",
    "\n",
    "## スカラーとベクトルの違い\n",
    "- スカラー\n",
    "    - 普通の数で四則演算可能\n",
    "    - ベクトルに対する係数になれる\n",
    "- ベクトル\n",
    "    - 大きさと向きを持ち、矢印で図示される\n",
    "    - スカラーのセットで表示される\n",
    "\n",
    "## 行列\n",
    "\n",
    "- ベクトルの変換に使う便利な道具\n",
    "- 変換後の要素のある一つは元の要素の全てから影響を受けている\n",
    "- 要素の数さえ変更可能\n",
    "- 行列が持つ大きさみたいなものが行列式\n",
    "\n",
    "## 固有値と固有ベクトル\n",
    "\n",
    "- ある行列 $A$ に対して、以下の式が成り立つような、特殊なベクトル $\\vec{x}$ と、右辺の係数 $\\lambda$ がある\n",
    "\n",
    "$$ A\\vec{x} = \\lambda \\vec{x} $$\n",
    "\n",
    "- 行列 $A$ とその特殊なベクトル $\\vec{x}$ の積は、ただのスカラーの数 $\\lambda$ とその特殊なベクトル $\\vec{x}$ との積と同じになる！\n",
    "- この特殊なベクトル $\\vec{x}$ とその係数 $\\lambda$ を、行列 $A$ に対する、固有ベクトル、固有値という\n",
    "\n",
    "### 利点\n",
    "\n",
    "- 情報量削減、計算の簡易化が行える\n",
    "- 暗号化や圧縮で使うことができる\n",
    "\n",
    "### 気づき\n",
    "\n",
    "- なんでもない $AB=CD$ の行列の式から、固有値と固有ベクトルを抜き出す第一ステップはどうすれば？\n",
    "    - $AB=CD$ のように複数の行列が含まれる式を相手にしておらず、あくまでAという一つの行列に対して固有値と固有ベクトルがある\n",
    "\n",
    "## 固有値分解\n",
    "\n",
    "- 固有値分解により行列で持つデータを整理可能\n",
    "- 固有値を対角線上に並べた行列を作成するにあたり、大きい順、または小さい順に並べる場合が多く、その場合は固有ベクトルもそれに合わせ並べる\n",
    "\n",
    "## 特異値分解\n",
    "\n",
    "- 固有値分解は正方形で分解できていたが、自分自身とその転置をかけて正方行列を作り出し、固有値分解することが特異値分解\n",
    "- $MM^t$ して特異値の二乗したようなものが特異値になっている。ただし完全な二乗ではない。\n",
    "- 単位行列は転置するだけで逆行列になる\n",
    "- 先生の機械学習に関しての話のメモ\n",
    "    - 特異値が似ている観点で画像・音声を分類できるかもしれない\n",
    "    - 特異値の左右特異ベクトルの小さい特異値を切り捨てることで画像を変更できる\n",
    "    - レンズの構造は行列で表せる。ピントが合ってないのは固有値・特異値に相当する箇所がゼロで近似されている状態\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8XKJrfWVZvl"
   },
   "source": [
    "# 第２章：確率・統計\n",
    "\n",
    "## 確率\n",
    "\n",
    "- 種類　→　頻度確率（客観確率）／ベイズ確率（主観確率）\n",
    "- 頻度確率（客観確率）\n",
    "    - 実験して確認することができる\n",
    "- ベイズ確率（主観確率）\n",
    "    - 自身の信念の確信度合い\n",
    "\n",
    "## 条件付き確率\n",
    "\n",
    "- 同時に起きる事象の確率は掛け算、順序入れ替え可能\n",
    "\n",
    "## ベイズ則の利用\n",
    "\n",
    "- 主観であろうが客観であろうがどちらでも使える\n",
    "- 主観であることが論理的でない、ということではない\n",
    "- 条件付き確率、独立な事象の同時確率の式を変形すると、違う条件下の確率式に変換できる\n",
    "    - 条件を入れ替えることができる\n",
    "\n",
    "## 確率変数と確率分布\n",
    "\n",
    "- 注意\n",
    "    - 確率変数と確率分布はしばしば混乱するので注意\n",
    "    - 確率変数は数値\n",
    "    - 確率分布は確率が発生する分布\n",
    "- 発生した事象(確率変数)とその確率をかけると期待値(平均値)が求まる\n",
    "- 事象が連続し平均値計算が困難なら、インテグラルを取れば良い\n",
    "\n",
    "## 分散と共分散\n",
    "\n",
    "- 注意\n",
    "    - 平均値だけではわからないデータの側面がある\n",
    "    - 分散は絶対値ではなく二乗を使いマイナスを取っている(計算が楽でミスが少ない)\n",
    "\n",
    "### 気づき\n",
    "\n",
    "- 分散は偏差の二乗和を取っているため、計算結果も二乗した状態になり、単位が変わる\n",
    "    - $cm -> cm^2$\n",
    "\n",
    "### 補足より\n",
    "\n",
    "- 関数 $E$ は平均を求めるが、 *線形性がある* とはどういうことか。\n",
    "    - 関数 $E$ に線形性があれば、渡される関数の性質がわからなくてもある程度のことができるということ\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(f + g) &= E(f) + E(g) && \\text{⇐線形性があり、左記が成立する} \\\\\n",
    "E(2f) &= 2 E(f) && \\text{⇐値が変わらないものは外に出せる} \\\\\n",
    "E(1) &= 1 && \\text{⇐1の平均は1、E()に定数が入ると定数そのものとなる}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- 分散の式変形\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Var(f) &= E( (f - \\boxed{E(f)})^2 ) && E(f) \\text{は定数} \\\\\n",
    "       &= E( f^2 \\underline{-2E(f) \\cdot f} + \\boxed{E(f)^2} ) && E(f)^2 \\text{は定数} \\\\\n",
    "       &= E(f^2) + E( \\underline{-2E(f)} \\cdot f ) + E( \\boxed{E(f)^2} ) && \\text{〃} -2E(f) \\text{は定数} \\\\\n",
    "       &= E(f^2) \\underline{-2E(f)} \\cdot E(f) + \\boxed{E(f)^2} && \\text{〃 〃} \\\\\n",
    "       &= E(f^2) - E(f)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- 共分散の式変形\n",
    "\n",
    "$$\n",
    "\\require{cancel}\n",
    "\\begin{align}\n",
    "Cov(f,g) &= E( (f-E(f)) \\cdot (g-E(g)) ) \\\\\n",
    "         &= E( f \\cdot g \\underline{-f \\cdot E(g)} \\ \\underline{-E(f) \\cdot g} + \\fbox{E(f)E(g)} ) \\\\\n",
    "         &= E(f \\cdot g) - E(g)E(f) \\cancel{ - E(f)E(g) + E(f)E(g) } \\\\\n",
    "         &= E(f \\cdot g) - E(f)E(g)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "## 様々な確率分布\n",
    "\n",
    "- ベルヌーイ分布\n",
    "    - オモテとウラなど２値しか取らないものの分布\n",
    "    - ２値の発生確率が等しくなくても良い\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x &= 0) = 1-u\\\\\n",
    "P(x &= 1) = u\\\\\n",
    "\\\\\n",
    "& \\text{一つで考えると}\\\\\n",
    "\\\\\n",
    "P(X &= x) = u^x (1-u)^1-x\\\\\n",
    "P(X &= x|u) \\\\\n",
    "    & \\text{⇑表裏の確率が違う場合}\\\\\n",
    "\\\\\n",
    "& \\text{元々はもっとシンプルだった}\\\\\n",
    "\\\\\n",
    "P(x &= 0) = λ0 \\\\\n",
    "P(x &= 1) = λ1 \\\\\n",
    "λ0 &+ λ1 = 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- マルチヌーイ分布\n",
    "    - ベールヌイ分布の復数版（さいころ）\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(X=1) &= λ1\\\\\n",
    "P(X=2) &= λ2\\\\\n",
    "P(X=3) &= λ3\\\\\n",
    "λ1+λ2+λ3 \\ ... \\ &= 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- 二項分布\n",
    "    - ベルヌーイ分布の親戚で多試行\n",
    "\n",
    "- ガウス分布\n",
    "    - 釣鐘型の分布を作るために $e^{-|x|} -> e^{x^2}$ とするアイデアがベースにある\n",
    "    - 確率分布を生成する式の $exp$ 両脇にある係数は面積を１とするための調整と思って良い\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjGuhvuAVhMI"
   },
   "source": [
    "# 第３章：情報理論\n",
    "\n",
    "## 自己情報量\n",
    "\n",
    "- 対数の底が２のとき、単位はビット(bit)\n",
    "- 対数の低がネイピアのeのとき、単位は(nat)\n",
    "\n",
    "$$ I(x) = -log(P(x)) = log(W(x)) $$\n",
    "\n",
    "- Pは小さくなる(珍しくなる)とWは大きくなる(珍しくない)\n",
    "- Wは情報量である\n",
    "- 情報量について $log$ の中では掛け算だが、 $log$ 同士にすると足し算表記にできる。以下参照\n",
    "\n",
    "$$\n",
    "A * B = 2^a * 2^b = 2^a+b\\\\\n",
    "log_2(A*B) = a + b = log_2 A + log_2 B\\\\\n",
    "$$\n",
    "\n",
    "- なぜ逆数がマイナスかは下記参照\n",
    "\n",
    "$$\n",
    "log \\frac{ 1 }{ A } = -log A\\\\\n",
    "A = 2^a\\\\\n",
    "\\frac{ 1 }{ A } = \\frac{ 1 }{2^a} = 2^{-a}\n",
    "$$\n",
    "\n",
    "### 疑問\n",
    "\n",
    "- ビットは最小の情報量として0/1のビットにしたとしても、ネイピアのeはなぜナット？\n",
    "    - Wikipedia より [natは\"natural unit of information\"（情報の自然単位）の略](https://ja.wikipedia.org/wiki/%E3%83%8A%E3%83%83%E3%83%88_(%E5%8D%98%E4%BD%8D))\n",
    "    - ビットは二進対数を使用するのに対し、ナットは自然対数を使用するからだそう\n",
    "\n",
    "## シャノンエントロピー\n",
    "\n",
    "- 元の情報量に対して、どれだけ情報が増えたか、で人間は見ている\n",
    "- 物理学上の話でいえば、エントロピーは複雑さがどれだけ増えたか？の意味\n",
    "- 物理学上の話でいえば、エントロピーの定義は $\\Delta E = T \\Delta S$\n",
    "\n",
    "| 変化 | 増加量 | 結果 |\n",
    "| - | - | - |\n",
    "| 10個 -> 11個 | 10個に対し1個で増加量 $\\frac{1}{10} = 0.1$ | 増えたことがあまりわからない |\n",
    "| 1個 -> 2個 | 1個に対し1個で増加量 $\\frac{1}{1} = 1$ | 増えたことがわかりやすい |\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\Delta w}{W} &= \\Delta I\\\\\n",
    "\\\\\n",
    "dI      &= \\frac{dw}{W}\\\\\n",
    "\\int dI &= \\int \\frac{dw}{W}\\\\\n",
    "I       &= \\int \\frac{1}{W} dw\\\\\n",
    "        &= \\log_e W\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- シャノンエントロピーは平均エントロピー(平均=期待値)\n",
    "- 微分エントロピーともいうが、微分しているわけではない（誤訳？）\n",
    "- 自己情報量の期待値\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H(x) &= E(I(x))\\\\\n",
    "     &= -E(\\log (P(x)))\\\\\n",
    "     &= - \\Sigma (P(x) \\log (P(x)))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "## カルバック・ライブラー　ダイバージェンス\n",
    "\n",
    "- 同じ事象・確率変数における異なる確率分布 $P,Q$ の違いを表す\n",
    "- 古い情報から $Q$ がわかっていて、新しい実験や統計を取った結果新しい $P$ が手に入ったとする。  \n",
    "珍しいと思っていたニュースの価値がどれだけ変わったかと見ることができる。\n",
    "\n",
    "$$\n",
    "D_{KL}(P \\parallel Q)\n",
    " = \\mathbb{E}_{\\mathbb{X}\\sim P}[\\log \\frac{P(x)}{Q(x)}]\n",
    " = \\mathbb{E}_{\\mathbb{X}\\sim P}[\\log P(x) - \\log Q(x)]\n",
    "$$\n",
    "\n",
    "## 交差エントロピー\n",
    "\n",
    "- KLダイバージェンスの一部分を取り出したもの\n",
    "- $Q$ についての自己情報量を $P$ の分布で平均している\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H(P,Q) &= H(P) + D_{KL}(P \\parallel Q)\\\\\n",
    "H(P,Q) &= -\\mathbb{E}_{\\mathbb{X}\\sim P} \\log Q(x)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- 交差エントロピーはKLダイバージェンスとは由来が違うかもしれない\n",
    "- おそらく一度に送れる通信量が小さい古い時代に役立ったのではないか\n",
    "    - $Q$ は必要なものを取捨選択し先に絞られたもの\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_応用数学.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
