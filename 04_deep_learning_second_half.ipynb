{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4fhror4LEgr"
   },
   "source": [
    "iStudy ACADEMY 現場で潰しが効くディープラーニング講座 視聴課題レポート 深層学習 後半1,2（講義動画と実装演習）\n",
    "<div style=\"text-align: right;\">【レポート作成者】S.Honda</div>\n",
    "\n",
    "# 深層学習 後半1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再帰型ニューラルネットワークについて\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section1 : 再帰型ニューラルネットワークの概念\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "erWaiWY6VPQ9"
   },
   "source": [
    "### 1-1 : RNN全体像\n",
    "\n",
    "- RNNとは\n",
    "  - RNN (Recurrent Neural Network : 再帰型ニューラルネットワーク) は、ニューラルネットワークを拡張し時系列データを扱えるようにしたもの\n",
    "- 時系列データとは\n",
    "  - 時間的順序を追って一定間隔ごとに観察され、しかも相互に統計的依存関係が認められるようなデータの系列\n",
    "    - ある時刻の値は、以前の時刻の変化の延長上\n",
    "    - ある時間の経過とともに値が変化していくようなデータ\n",
    "  - データの例\n",
    "    - 音声データ, テキストデータ, 株価データなど\n",
    "    - 店舗の日次売上データ, ホームページのアクセス数履歴, 工場設備のセンサデータなどなど\n",
    "  - 関心の対象 : どのようなトレンドや周期をもち、それに従って今後どのように変化するか\n",
    "- RNNの処理概要\n",
    "  - 順伝播時、一つ前の計算結果(中間層の活性化関数後の出力値)を保管しておく\n",
    "  - 次回の順伝播の計算時に **前回の出力結果 *  w + b** の計算を行い、中間層の追加の入力情報とする\n",
    "  - 時系列モデルを扱うには、初期の状態と過去の時間t-1の状態を保持し、そこから次の時間でのtを再帰的に求める再帰構造が必要になる\n",
    "- RNNの数学的記述\n",
    "  - $u^t = W_{(in)}x^t + W z^{t-1} + b$\n",
    "  - $z^t = f( W_{(in)}x^t + W z^{t-1} + b)$\n",
    "  - $v^t = W_{(out)} z^t + c$\n",
    "  - $y^t = g( W_{(out)} z^t + c)$\n",
    "\n",
    "`調査・考察`\n",
    "\n",
    "- 時系列に対応したニューラルネットワークが RNN(Recurrent Neural Network : 再帰型ニューラルネットワーク) だが、Recurrent Neural Network を木構造に拡張した Recursive Neural Network を RNN とも略し、紛らわしいので注意。\n",
    "- 多くの場合は、RNN は Recurrent Neural Network を指している事が多いが、自然言語処理の場合は Recursive Neural Network を指す場合があるようだ。\n",
    "- 回帰型ニューラルネットワーク、循環ニューラルネットワークとも訳される\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 : BPTT\n",
    "\n",
    "- BPTT (BackPropagation Through Time) は、 **誤差逆伝播法の一種** であり、誤差が時間をさかのぼって逆伝播させる手法\n",
    "  - RNNの誤差を求める際には時間軸で展開するとイメージしやすい\n",
    "- 誤差逆伝播法を時系列に沿う形で実施する\n",
    "- RNNにおいてのパラメータの調整方法である\n",
    "- BPTTの数学的記述\n",
    "  - その1\n",
    "    - $\\displaystyle \\frac{\\partial E}{\\partial W_{(in)}} = \\frac{\\partial E}{\\partial u^t} \\left[\\frac{\\partial u^t}{\\partial W_{(in)}} \\right]^T = \\delta^t \\left[ x^t \\right]^T$\n",
    "    - $\\displaystyle \\frac{\\partial E}{\\partial W_{(out)}} = \\frac{\\partial E}{\\partial v^t} \\left[\\frac{\\partial v^t}{\\partial W_{(out)}} \\right]^T = \\delta^{out,t} \\left[ z^t \\right]^T$\n",
    "    - $\\displaystyle \\frac{\\partial E}{\\partial W} = \\frac{\\partial E}{\\partial u^t} \\left[\\frac{\\partial u^t}{\\partial W} \\right]^T = \\delta^t \\left[ z^{t-1} \\right]^T$\n",
    "    - $\\displaystyle \\frac{\\partial E}{\\partial b} = \\frac{\\partial E}{\\partial u^t} \\frac{\\partial u^t}{\\partial b} = \\delta^t$\n",
    "    - $\\displaystyle \\frac{\\partial E}{\\partial c} = \\frac{\\partial E}{\\partial v^t} \\frac{\\partial v^t}{\\partial c} = \\delta^{out,t}$\n",
    "  - その2\n",
    "    - $\\displaystyle u^t = W_{(in)}x^t + Wz^{t-1} + b$\n",
    "    - $\\displaystyle z^t = f( W_{(in)}x^t + Wz^{t-1} + b )$\n",
    "    - $\\displaystyle v^t = W_{(out)}z^t + c$\n",
    "    - $\\displaystyle y^t = g( W_{(out)}z^t + c )$\n",
    "  - その3\n",
    "    - $\\displaystyle \\frac{\\partial E}{\\partial u^t} = \\frac{\\partial E}{\\partial v^t} \\frac{\\partial v^t}{\\partial u^t} = \\frac{\\partial E}{\\partial v^t} \\frac{\\partial \\left\\{ W_{(out)}f(u^t)+c \\right\\} }{\\partial u^t} = f'(u^t)W_{(out)}^T \\delta^{out,t} = \\delta^t$\n",
    "    - $\\displaystyle \\delta^{t-1} = \\frac{\\partial E}{\\partial u^{t-1}} = \\frac{\\partial E}{\\partial u^t} \\frac{\\partial u^t}{\\partial u^{t-1}} = \\delta^t \\left\\{ \\frac{\\partial u^t}{\\partial z^{z-t}} \\frac{\\partial z^{t-1}}{\\partial u^{t-1}} \\right\\} = \\delta^t \\left\\{ W f'(u^{t-1}) \\right\\}$\n",
    "    - $\\displaystyle \\delta^{t-z-1} = \\delta^{t-z} \\left\\{ W f'(u^{t-z-1}) \\right\\}$\n",
    "  - その４ (パラメータの更新式)\n",
    "    - $\\displaystyle W_{(in)}^{t+1} = W_{(in)}^t - \\epsilon \\frac{\\partial E}{\\partial W_{(in)}} = W_{(in)}^t - \\epsilon\\sum_{z=0}^{T_t}\\delta^{t-z} \\left[ x^{t-z} \\right]^T$\n",
    "    - $\\displaystyle W_{(out)}^{t+1} = W_{(out)}^t - \\epsilon\\frac{\\partial E}{\\partial W_{(out)}} = W_{(in)}^t - \\epsilon\\delta^{out,t} \\left[ z^t \\right]^T$\n",
    "    - $\\displaystyle W^{t+1} = W^t - \\epsilon\\frac{\\partial E}{\\partial W} = W_{(in)}^t - \\epsilon\\sum_{z=0}^{T_t}\\delta^{t-z} \\left[ z^{t-z-1} \\right]^T$\n",
    "    - $\\displaystyle b^{t+1} = b^t - \\epsilon\\frac{\\partial E}{\\partial b} = b^t - \\epsilon\\sum_{z=0}^{T_t}\\delta^{t-z}$\n",
    "    - $\\displaystyle c^{t+1} = c^t - \\epsilon\\frac{\\partial E}{\\partial c} = c^t - \\epsilon\\delta^{out,t}$\n",
    "  - BPTTの全体像\n",
    "    - $\\displaystyle \\begin{align}\n",
    "E^t &= loss \\left( y^t,d^t \\right) \\\\\n",
    "    &= loss \\left( g \\left( W_{(out)}z^t + c \\right), d^t \\right) \\\\\n",
    "    &= loss \\left( g \\left( W_{(out)} \\underline{ f(W_{(in)}x^t + Wz^{t-1}+b) } +c \\right),d^t \\right)\n",
    "\\end{align}$\n",
    "    - $\\displaystyle W_{(in)}x^t + Wz^{t-1}+b\\\\\n",
    "    W_{(in)}x^t + W f \\left( u^{t-1} \\right) + b\\\\\n",
    "    W_{(in)}x^t + W f \\left( W_{(in)}x^{t-1} + Wz^{t-2} + b \\right) + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献・URL\n",
    "\n",
    "- [回帰型ニューラルネットワーク - Wikipedia](https://ja.wikipedia.org/wiki/%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)\n",
    "- [再帰型ニューラルネットワーク: RNN入門](https://qiita.com/kiminaka/items/87afd4a433dc655d8cfd)\n",
    "- [再帰型ニューラルネットワークの「基礎の基礎」を理解する　～ディープラーニング入門｜第3回](https://www.imagazine.co.jp/%E5%86%8D%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E3%80%8C%E5%9F%BA%E7%A4%8E%E3%81%AE%E5%9F%BA%E7%A4%8E%E3%80%8D/)\n",
    "- [ニューラルネットワークで時系列データの予測を行う](https://qiita.com/icoxfog417/items/2791ee878deee0d0fd9c)\n",
    "- [Backpropagation through time - wikipedia](https://en.wikipedia.org/wiki/Backpropagation_through_time)\n",
    "- [第4回　Backpropagation Through Time（BPTT）](https://book.mynavi.jp/manatee/detail/id=76172)\n",
    "- [Backpropagation Through Time - The First Cry of Atom](https://www.lewuathe.com/backpropagation-through-time.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確認テスト\n",
    "\n",
    "- Q : サイズ 5x5 の入力画像を、サイズ 3x3 のフィルタで畳み込んだ時の出力画像のサイズを答えよ。なおスライドは2、パディングは１とする。\n",
    "\n",
    "`考察`\n",
    "\n",
    "- 出力画像の $H = \\frac{H+2padding-filterH}{stride}+1 = \\frac{5 + 2 * 1 - 3}{2} + 1 = 3$\n",
    "- 出力画像の $W = \\frac{H+2padding-filterW}{stride}+1 = \\frac{5 + 2 * 1 - 3}{2} + 1 = 3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q : RNNのネットワークには大きく分けて３つの重みがある。  \n",
    "１つは入力から現在の中間層を定義する際にかけられる重み、１つは中間層から出力を定義する際にかけられる重みである。  \n",
    "残り１つの重みについて説明せよ。\n",
    "\n",
    "`考察`\n",
    "\n",
    "- RNNは前回の順伝播時の中間層出力を現在の中間層の入力とするが、そこには W,b を他と同様に重み・バイアスとして演算する。残り１つの重みはこれである。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q : 連鎖率の原理を使い、 $\\frac{\\Delta z}{\\Delta x}$ を求めよ。\n",
    "$$z = t^2$$\n",
    "$$t = x + y$$\n",
    "\n",
    "`考察(再掲)`\n",
    "\n",
    "$$ \\frac{\\Delta z}{\\Delta x} = \\frac{\\Delta z}{\\Delta t} \\cdot \\frac{\\Delta t}{\\Delta x} = 2t = 2(x + y)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q : 下図の $y_1$ を $x \\cdot s_0 \\cdot s_1 \\cdot w_{in} \\cdot w \\cdot w_{out}$ を用いて数式で表わせ。  \n",
    "※バイアスは任意の文字で定義せよ。  \n",
    "※また中間層の出力にシグモイド関数 $g(x)$ を作用させよ。\n",
    "\n",
    "<img src=\"./images/day3/section1_q4.png\" width=\"750px\" />\n",
    "\n",
    "`考察`\n",
    "\n",
    "- $z_1 = sigmoid(S_0 W + x_1 W_{(in)} + b)$\n",
    "- $y_1 = sigmoid(Z_1 W_{(out)} + c)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習の結果と考察\n",
    "\n",
    "`実施結果`\n",
    "\n",
    "- [演習 3_1_simple_RNN](./03_exercise/lesson_3/3_1_simple_RNN.ipynb)\n",
    "    - 変更箇所は【レポート提出者変更】とコメントで囲って記載\n",
    "\n",
    "`考察`\n",
    "\n",
    "- 活性化関数がシグモイドの場合、隠れ層（中間層）のノード数を64まで増やす範囲なら精度が向上することを観測できた。\n",
    "- パラメータの初期値（正規分布の乱数生成パラメータ）について、1.25程度まで上げる範囲なら精度が向上することを観測できた。それ以上の場合は不安定となり収束が遅くなった。\n",
    "- 学習率は0.15程度まで上げた時点で、精度が向上していることを観測できた。それ以上の場合は不安定となり収束が遅くなった。\n",
    "- 重みの初期化方法は、Heを用いると学習速度が早まった。Xavierは正答率のブレは少なくなるが学習速度は早まらなかった。\n",
    "- 活性化関数をシグモイド関数 から ReLU 関数に変更後、勾配爆発が発生。正答率が不安定かつ学習されなくなり、全く精度が向上しなかった。\n",
    "- 活性化関数を ReLU から tanh に変更すると、正答率が安定し学習速度が圧倒的に早まった。\n",
    "- 活性化関数が tanh の場合は精度が向上したため、hidden_layer_sizeを32,64と組み合わせてみた。勾配爆発が発生し、逆に安定しなくなってしまった。\n",
    "- どれか一つのパラメータ・活性化関数を選択・調整すればよいわけではなく、精度が良くなる想定が悪い組み合わせとなってしまう場合があり、簡単ではない。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 変更対象 | 誤差グラフ | - | - | - | - | 備考 |\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "| hidden_layer_size | <img src=\"./images/day3/3_1_hidden_layer_size_8.png\" width=\"750px\" /><br>8 | <img src=\"./images/day3/3_1_hidden_layer_size_16.png\" width=\"750px\" /><br>**16 (基準)** | <img src=\"./images/day3/3_1_hidden_layer_size_32.png\" width=\"750px\" /><br>32 | <img src=\"./images/day3/3_1_hidden_layer_size_64.png\" width=\"750px\" /><br>64 | <img src=\"./images/day3/3_1_hidden_layer_size_128.png\" width=\"750px\" /><br>128 | - |\n",
    "| weight_init_std | <img src=\"./images/day3/3_1_wait_init_std_0.50.png\" width=\"750px\" /><br>0.50 | <img src=\"./images/day3/3_1_wait_init_std_0.75.png\" width=\"750px\" /><br>0.75 | <img src=\"./images/day3/3_1_wait_init_std_1.00.png\" width=\"750px\" /><br>**1.00 (基準)** | <img src=\"./images/day3/3_1_wait_init_std_1.25.png\" width=\"750px\" /><br>1.25 | <img src=\"./images/day3/3_1_wait_init_std_1.50.png\" width=\"750px\" /><br>1.50 | - |\n",
    "| learning_rate | <img src=\"./images/day3/3_1_learning_rate_0.01.png\" width=\"750px\" /><br>0.01 | <img src=\"./images/day3/3_1_learning_rate_0.05.png\" width=\"750px\" /><br>0.05 | <img src=\"./images/day3/3_1_learning_rate_0.10.png\" width=\"750px\" /><br>**0.10 (基準)** | <img src=\"./images/day3/3_1_learning_rate_0.15.png\" width=\"750px\" /><br>0.15 | <img src=\"./images/day3/3_1_learning_rate_0.20.png\" width=\"750px\" /><br>0.20 | - |\n",
    "| 重みの初期化方法 | <img src=\"./images/day3/3_1_default.png\" width=\"750px\" /><br>**None (基準)** | <img src=\"./images/day3/3_1_initial_xavier.png\" width=\"750px\" /><br>Xavier | <img src=\"./images/day3/3_1_initial_he.png\" width=\"750px\" /><br>He | - | - | - |\n",
    "| 中間層の活性化関数 | <img src=\"./images/day3/3_1_initial_he.png\" width=\"750px\" /><br>**sigmoid (基準)** | <img src=\"./images/day3/3_1_activation_relu.png\" width=\"750px\" /><br>ReLU <span style=\"color: red\">**(勾配爆発)**</span> | <img src=\"./images/day3/3_1_activation_tanh.png\" width=\"750px\" /><br>tanh | <img src=\"./images/day3/3_1_activation_tanh_hidden_layer_size_32.png\" width=\"750px\" /><br>tanh(hidden_layer_size:32) <span style=\"color: red\">**(勾配爆発)**</span> | <img src=\"./images/day3/3_1_activation_tanh_hidden_layer_size_64.png\" width=\"750px\" /><br>tanh(hidden_layer_size:64) <span style=\"color: red\">**(勾配爆発)**</span> | - |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8XKJrfWVZvl"
   },
   "source": [
    "## Section2 : LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全体\n",
    "\n",
    "- RNNの課題\n",
    "  - 時系列を辿れば辿るほど、勾配消失する\n",
    "  - よって長い時系列の学習が困難\n",
    "- 解決策\n",
    "  - 勾配消失の解決方法とは別で、構造自体を変えて解決したのがLSTM\n",
    "\n",
    "### LSTMとは\n",
    "\n",
    "- LSTM(Long short-term memory)は、RNN(Recurrent Neural Network)の拡張として1995年に登場\n",
    "- 時系列データ(sequential data)に対するモデル、あるいは構造(architecture)の一種\n",
    "- 名前は Long term memory(長期記憶) と Short term memory(短期記憶) という神経科学における用語から取られている\n",
    "- LSTM は RNN の中間層のユニットを LSTM block と呼ばれるメモリと3つのゲートを持つブロックに置き換えることで実現されている\n",
    "\n",
    "### 勾配消失問題とは何であったか\n",
    "\n",
    "- 誤差逆伝搬法が下位層に進んで行くに連れて、勾配がどんどん緩やかになっていく\n",
    "- そのため勾配降下法による更新では、下位層のパラメータはほとんど変わらず、訓練は最適値に収束しなくなる\n",
    "\n",
    "### 勾配爆発とは\n",
    "\n",
    "- 勾配が層を逆伝播するごとに指数関数的に大きくなっていくこと\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 : CEC\n",
    "\n",
    "- 定誤差カルーセル(Constant Error Carousel : CEC) と呼ぶ\n",
    "- 勾配消失および勾配爆発の解決方法として、勾配を１として解決を目指したもの\n",
    "- 課題\n",
    "  - 入力データについて、時間依存度に関係なく重みが一定\n",
    "  - よって、ニューラルネットワークの学習特性が無い\n",
    "    - 入力層→隠れ層への重み　：　入力重み衝突\n",
    "    - 隠れ層→出力層への重み　：　出力重み衝突\n",
    "  - 入力ゲートと出力ゲートによって一律ではなくなり重みの問題は解決出来る\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 : 入力ゲートと出力ゲート\n",
    "\n",
    "- 入力・出力ゲート\n",
    "  - 入力ゲート(Input Gate) と 出力ゲート(Output Gate) を追加することで、それぞれに重みを設置することが出来る\n",
    "  - 重みは行列 $W, u$ で可変可能とした\n",
    "- 結論\n",
    "  - CECの重みが一律化する問題が解決される\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 : 忘却ゲート\n",
    "\n",
    "- 忘却ゲート\n",
    "  - CECは過去の情報が全て保管され過去の情報が現在に影響を与え続ける\n",
    "  - 過去の情報が要らなくなった場合、そのタイミングで情報を忘却する機能が必要になる\n",
    "  - そのニーズより 忘却ゲート(Forget Gate) が考案された\n",
    "- 結論\n",
    "  - 重みは行列 $W, u$ で可変可能、CECの重みが存在しない点も解決\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 : 覗き穴結合\n",
    "\n",
    "- 現時点の要望\n",
    "  - CECの保存されている過去の情報を、任意のタイミングで他のノードに伝播させたり、あるいは任意のタイミングで忘却させたい\n",
    "  - CEC自身の値は、ゲート制御に影響を与えていない\n",
    "- 結論\n",
    "  - CEC自身の値に、重み行列を介して伝播可能とした構造とし、それを覗き穴結合(Peephole Connection)と言う\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献・URL\n",
    "\n",
    "- [長・短期記憶 - Wikipedia](https://ja.wikipedia.org/wiki/%E9%95%B7%E3%83%BB%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6)\n",
    "- [わかるLSTM ～ 最近の動向と共に](https://qiita.com/t_Signull/items/21b82be280b46f467d1b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確認テスト\n",
    "\n",
    "- Q : シグモイド関数を微分したとき、入力値が０の時に最大値を取る。その値として正しいものを選択肢から選べ。\n",
    "  - (1) 0.15\n",
    "  - (2) 0.25\n",
    "  - (3) 0.35\n",
    "  - (4) 0.45\n",
    "\n",
    "`考察（再掲）`\n",
    "\n",
    "  - シグモイド関数 -> $sigmoid(x)$  \n",
    "  - シグモイド関数の導関数 -> $(1 - sigmoid(x)) * sigmoid(x)$  \n",
    "  - $sigmoid(0) = 0.5$ なので導関数の値は $(1 - 0.5) * 0.5 = 0.25$\n",
    "    - よって **(2) 0.25**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q : 以下の文章をLSTMに入力し空欄に当てはまる単語を予測したいとする。  \n",
    "文中の「とても」という言葉は空欄の予測において、なくなってしまっても影響を及ぼさないと考えられる。  \n",
    "このような場合、どのゲートが作用すると考えられるか。  \n",
    "**「映画面白かったよね。どころで、とてもお腹が空いたから何か____。」**\n",
    "\n",
    "`考察`\n",
    "\n",
    "- なくなってしまっても問題はないことから、忘却ゲートが作用すると考えられる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjGuhvuAVhMI"
   },
   "source": [
    "## Section3 : GRU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTMの課題\n",
    "  - 構造を見たとおり、パラメータ数が多く、計算負荷が高くなる\n",
    "  - 計算負荷が高いためアウトプットを出すまで時間がかかる\n",
    "- GRUとは\n",
    "  - ゲート付き回帰型ユニット(Gated recurrent unit : GRU) と呼ぶ。\n",
    "  - LSTMでは多数存在したパラメータを大幅に削減し、精度は同等またはそれ以上が望める形へ構造を改善、スリム化された\n",
    "- GRUのメリット\n",
    "  - 計算負荷がLSTMと比較して、かなり低い\n",
    "- 注意点\n",
    "  - なんでもLSTMよりGRUのほうが優れているわけではなく、対象の問題(内容)による\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献・URL\n",
    "\n",
    "- [ゲート付き回帰型ユニット - Wikipedia](https://ja.wikipedia.org/wiki/%E3%82%B2%E3%83%BC%E3%83%88%E4%BB%98%E3%81%8D%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%A6%E3%83%8B%E3%83%83%E3%83%88)\n",
    "- [わかるLSTM ～ 最近の動向と共に](https://qiita.com/t_Signull/items/21b82be280b46f467d1b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確認テスト\n",
    "\n",
    "- Q : LSTMとCECが抱える課題について、それぞれ簡潔に述べよ。\n",
    "\n",
    "`考察`\n",
    "\n",
    "| 手法  | 課題 |\n",
    "| -    | - |\n",
    "| LSTM | 多数のパラメータが存在し、計算負荷が高いためアウトプットに時間がかかる |\n",
    "| CEC  | 勾配を１とし重みがないため、学習特性を持たず、学習できない |\n",
    "\n",
    "- Q : LSTMとGRUの違いを簡潔に述べよ。\n",
    "\n",
    "`考察`\n",
    "\n",
    "- LSTMはパラメータ数が多く、GRUは少ない。パラメータ数が違うことで、計算量に差がある。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section4 : 双方向RNN\n",
    "\n",
    "- 双方向RNN(（bi-directional RNN) と呼ぶ\n",
    "- 順方向と逆方向に伝播したときの中間層表現をあわせたものが特徴量となる\n",
    "- GRUもLSTMもRNNであるため、双方向LSTM (Bidirectional LSTM : BLSTM) というものもある\n",
    "- LSTM は 双方向性や復数段の組み合わせにより表現力を向上させることが出来る\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNでの自然言語処理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section5 : Seq2Seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoder-Decoderモデルの一種であり、時系列データを生成する問題について、現在有効とされている手法が Seq2seq\n",
    "- 入力の時系列データに対してEncoderが有効な情報を詰め込んだ符号へと変換\n",
    "- この符号を使用してDecoderが再度変換を行い、出力となる時系列データを生成する\n",
    "- 主に機械対話や機械翻訳などに利用されている\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1 : Encoder RNN\n",
    "\n",
    "- ユーザーがインプットしたテキストデータを単語等のトークンに区切り渡す構造\n",
    "  - 【Talking】\n",
    "    - 文章を単語等のトークン毎に分割\n",
    "    - トークン毎にIDが付与\n",
    "  - 【Embedding】\n",
    "    - IDからトークンを表す分散表現ベクトルに変換\n",
    "  - 【Encodder RNN】\n",
    "    - ベクトルを順番にRNNへ入力していく\n",
    "- 処理手順\n",
    "  1. vec1 を RNNに入力し、 hidden state を出力\n",
    "    - vec1 --[INPUT]--> RNN --[OUTPUT]--> hidden state\n",
    "    - hidden state + vec2 --[INPUT]--> RNN --[OUTPUT]--> hidden state ... 繰り返す\n",
    "  2. 最後の vec を入れた時の hidden state を final state として取っておく\n",
    "  3. final state が thought vector と呼ばれ、入力した文の意味を表すベクトルとなる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2 : Decoder RNN\n",
    "\n",
    "- システムがアウトプットデータを単語等のトークン毎に生成する構造\n",
    "- 処理手順\n",
    "  1. 【Decoder RNN】\n",
    "    - Encoder RNN の final state(thought vector) から、各トークンの生成確率を出力\n",
    "    - final state を Decoder RNN の initial state として設定、 Embedding を入力\n",
    "  2. 【Sampling】\n",
    "    - 生成確率に基づいてトークンをランダムに選択\n",
    "  3. 【Embedding】\n",
    "    - Sampling で選ばれたトークンを Embedding して Decoder RNN への次の入力にする\n",
    "  4. 【Detokenize】\n",
    "    - 上記３手順を繰り返し、Sampling で得られたトークンを文字列へ復元\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3 : HRED\n",
    "\n",
    "- Seq2seqの課題\n",
    "  - 一問一答しかできない\n",
    "  - 問に対して文脈も何もなく、ただ応答が行われ続ける\n",
    "- HREDとは\n",
    "  - 階層的回帰型エンコーダー・デコーダー (Hierarchical Recurrent Encoder-Decoder : HRED)\n",
    "  - 過去 n-1 個の発話から次の発話を生成\n",
    "  - Seq2seq では会話の文脈無視で応答がされていた\n",
    "  - HRED では前の単語の流れに沿い応答があるため、より人間らしい文章が生成される\n",
    "- HREDの構造\n",
    "  - Seq2seq + Context RNN\n",
    "  - Seq2Seq は Encoder RNN, Decoder RNN の2段構成だったが、HRED は Encoder RNN, Context RNN, Decoder RNN の3段構成\n",
    "    - Encoder RNN: 一つ一つの文章（会話なら過去の一つ一つの発言）をそれを表すベクトルに変換する\n",
    "    - Context RNN: Encoder のまとめた各文章の系列をまとめて、これまでの会話コンテキスト全体を表すベクトルに変換する\n",
    "    - Decoder RNN: Context RNN の情報から応答を生成する\n",
    "  - Context RNN が加えられていることにより、過去の発話の履歴を加味した返答が可能となった\n",
    "- HREDの課題\n",
    "  - 確率的な多様性が字面にしかない\n",
    "  - 会話の流れのような多様性がない\n",
    "    - 同じコンテキスト（発話リスト）を与えられても答えの内容が毎回会話の流れとしては同じものしか出力されない\n",
    "  - 短く情報量に乏しい答えをしがち\n",
    "    - 短いよくある答えを学びやすい\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-4 : VHRED\n",
    "\n",
    "- VHREDとは\n",
    "  - HRED に VAE の潜在変数の概念を追加し、 HRED の課題を解決\n",
    "  - HRED では文脈に沿う回答が生成できたが、同じ文章に対して同じ回答しか生成できなかった\n",
    "  - VHRED では回答の内容が変わり、回答に多様性がある\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-5 : VAE\n",
    "\n",
    "#### オートエンコーダー\n",
    "\n",
    "- オートエンコーダとは\n",
    "  - 教師なし学習の一つ\n",
    "  - 学習時の入力データは訓練データのみで教師データは利用しない\n",
    "  - データを表現する特徴を獲得するためのニューラルネットワーク\n",
    "  - `自己符号化器` と表現されたりもする\n",
    "- 具体例\n",
    "  - MNISTを使い 28x28 の数字画像を入力し、同じ画像を出力するニューラルネットワークということ\n",
    "- 構造\n",
    "  - Encoder : 入力データから潜在変数 z に変換するニューラルネットワーク\n",
    "  - Decoder : 潜在変数 z を入力し元画像を復元するニューラルネットワーク\n",
    "- メリット\n",
    "  - 次元削減が行える\n",
    "  - z の次元が入力データより小さい場合、次元削減とみなせる\n",
    "- 注意点\n",
    "  - １を表す画像に対し１の確率を出力するクラス分けではない\n",
    "  - zの次元が入力より小さくても、極力入力と同じデータを出力するということ\n",
    "\n",
    "#### VAE\n",
    "\n",
    "- オートエンコーダの課題\n",
    "  - 潜在変数 z にデータを押し込めているものの、その中身がどの状態か不明\n",
    "- VAEとは\n",
    "  - Variational Autoencoder\n",
    "  - 潜在変数 z に確立分布 z〜N(0,1) を仮定したもの\n",
    "  - 言い換えれば、データを潜在変数 z の確率分布に押し込めることを可能にしたもの\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献・URL\n",
    "\n",
    "- [自然言語処理について勉強してみた(その5：Seq2Seq・Attention)](https://tsunotsuno.hatenablog.com/entry/2019/02/12/000000)\n",
    "- [DeepLearning における会話モデル： Seq2Seq から VHRED まで](https://qiita.com/halhorn/items/646d323ac457715866d4)\n",
    "- [Variational Autoencoder徹底解説](https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確認テスト\n",
    "\n",
    "- Q : 下記の選択肢から、seq2seqについて説明しているものを選べ。\n",
    "  1. 時刻に関して順方向と逆方向のRNNを構成し、それら２つの中間層表現を特徴量として利用するものである。\n",
    "  2. RNNを用いたEncoder-Decoderモデルの一種であり、機械翻訳などのモデルに使われる。\n",
    "  3. 構文木などの木構造に対して、隣接単語から表現ベクトル（フレーズ）を作るという演算を再帰的に行い（重みは共通）、文全体の表現ベクトルを得るニューラルネットワークである。\n",
    "  4. RNNの一種であり、単純なRNNにおいて問題となる勾配消失問題をCECとゲートの概念を導入することで解決したものである。\n",
    "\n",
    "`考察`\n",
    "\n",
    "`2. RNNを用いたEncoder-Decoderモデルの一種であり、機械翻訳などのモデルに使われる。` がseq2seqについて説明している。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q : Seq2seq と HRED、HRED と VHRED の違いを簡潔に述べよ。\n",
    "\n",
    "`考察`\n",
    "\n",
    "- Seq2seq と HRED\n",
    "  - Seq2seq は一問一答しかできなかったが、 HRED は文脈に即した回答が生成できる\n",
    "- HRED と VHRED\n",
    "  - HRED の文脈に沿う回答が生成できたが、毎回同じ回答しか生成できなかった。VHREDは回答に多様性が出る。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q : VAE に関する下記の説明文中の空欄に当てはまる言葉を答えよ。  \n",
    "自己符号化器の存在変数に____を導入したもの。\n",
    "\n",
    "`考察`\n",
    "\n",
    "- 確率分布\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section6 : Word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section7 : Attention Mechanism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# 深層学習 後半2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section1 : Tensorflow の実装演習\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section2 : 強化学習\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_深層学習_後半.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
